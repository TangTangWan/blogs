{"pages":[],"posts":[{"title":"Disruptor介绍及原理讲解","text":"简介Disruptor是一个无锁有界内存队列开源框架，最大的特点就是性能非常高高高。很多知名项目都有用到它比如我们熟悉的Log4j 2 . 本文主要介绍它如何做到高性能，以及具体的框架设计。 为什么性能这么强大？主要是因为有这三个法宝：RingBuffer，无锁设计和缓存行填充。 RingBufferDisruptor底层采用RingBuffer的结构，RingBuffer大家都知道，就是一个循环使用下标的数组嘛。 计算访问下标的时候，通过取余计算 （cursor % size )来得到数组下标。（一个trick是，当size是2的幂的时候，可以用 cursor &amp; (size - 1) 来快速计算下标。所以Disruptor指定size必须是2的幂。） 用RingBuffer的好处： 不需要清数据，用新数据去覆盖旧数据，减少GC 底层是数组，充分利用缓存 无锁设计怎么做到的？ 在Disruptor中，生产者和消费者有各自的游标，用来指导需要写入或读取的位置。 消费者对节点的唯一操作是读而不是写，因此不需要加锁。 只有一个生产者的时候，只需要保证生产者的游标不会超过最慢的消费者一圈（即，不会把消费者还没读完的数据覆盖掉）即可，因此不需要锁。 当有多个生产者时，Disruptor采用CAS来保证游标的线程安全。在整个复杂的框架中，只有这一个地方出现多线程竞争修改同一个变量值。具体的交互在后面讲。 （另一方面，用volatile来标记游标，采用内存屏障来代替锁？） 缓存行填充先来了解一个概念，“伪共享”。 我们知道计算机有多级的缓存体系，越靠近CPU的缓存，速度越快，容量越小。而缓存由很多cache line组成，每个cache line通常是64bytes，所以一个cache line通常可以缓存8个long变量。从内存中拉取数据的时候，会把相邻的数据都一起加载到缓存中。在某些情况下这个缓存行优势会失效，导致并发速度反而下降了，这种情况称为伪共享。以下是一个典型的例子： 假设有两个线程Thread1和Thread2，分别在Core1和Core2上运行。有两个变量head和tail由它们共享，Thread1只读写head， Thread2只读写tail。理想情况下它们不应该有干扰，但是我们可以看到，当Thread1写入head以后，其他Core对应的cache line被都置为失效，也就意味着Core2想要读写tail，需要从内存中重新读取，而这显然是一种浪费。 我们可以通过缓存行填充来解决这类问题： 1234567891011121314class LhsPadding{ protected long p1, p2, p3, p4, p5, p6, p7;} class Value extends LhsPadding{ protected volatile long value;} class RhsPadding extends Value{ protected long p9, p10, p11, p12, p13, p14, p15;} 在Disruptor中，游标做了类似的处理。 在由我们自己定义的Event类中，也值得这样做。如果有不同的生产者往不同的字段写入（？），我们要确保各个字段之间不会出现伪共享。 具体设计直觉上理解一下Disruptor的设计：Disruptor通过对游标的管理，保证任何时候只有一个生产者去写一个槽，就省了很多并发问题；只要好好看好游标就行了。 消费先从比较好理解的消费者讲起。 在Disruptor中，消费者被称为EventProcessor，通过SequenceBarrier和RingBuffer交互。 如上图Stage2所示，事件处理器的最大序号是16.它向SequenceBarrier调用waitFor（17）以获得17格中的数据。如果没有数据写入RingBuffer，Stage2事件处理器将挂起等待下一个序号。但是，如上图所示的情况，RingBuffer已经被填充到18格，所以waitFor函数将返回18并通知事件处理器，它可以读取包括直到18格在内的数据，如下图所示。 你应该已经感觉得到，这样做是怎样有助于平缓延迟的峰值了——以前需要逐个节点地询问“我可以拿下一个数据吗？现在可以了么？现在呢？”，消费者现在只需要简单的说“当你拿到的数字比我这个要大的时候请告诉我”，函数返回值会告诉它有多少个新的节点可以读取数据了。因为这些新的节点的确已经写入了数据（Ring Buffer本身的序号已经更新），而且消费者对这些节点的唯一操作是读而不是写，因此访问不用加锁。这太好了，不仅代码实现起来可以更加安全和简单，而且不用加锁使得速度更快。 另一个好处是——你可以用多个消费者去读同一个RingBuffer ，不需要加锁，也不需要用另外的队列来协调不同的线程(消费者)。这样你可以在Disruptor的协调下实现真正的并发数据处理。 生产向RingBuffer写入数据需要经过两阶段提交。 只有一个发布者时首先，发布者必须确定RingBuffer中下一个可以插入的格, RingBuffer持有最近写入格的序号（下图中的18格），从而确定下一个插入格的序号。RingBuffer通过检查所有EventProcessor正在从RingBuffer中读取的当前序号来判断下一个插入格是否空闲，只需要保证下一个插入格已经被所有EventProcessor读取过即可。 发现了下一个插入格: 当发布者得到下一个序号后，它可以获得该格中的对象，并可以对该对象进行任意操作。你可以把格想象成一个简单的可以写入任意值的容器。 同时，在发布者处理19格数据的时候，RingBuffer的序号依然是18，所以其他事件处理器将不会读到19格中的数据。 对象的改动保存进了RingBuffer： 最终，发布者将数据写入19格后，通知RingBuffer发布19格的数据。这时，RingBuffer更新序号并且所有从RingBuffer读数据的事件处理器都可以看到19格中的数据。 总结一下，发布者需要先申请一个可写入的位置，然后再写入然后提交，这是一个明显的两阶段提交设计。 有多个发布者时单生产者的情况比较简单，当有多个生产者时，申请写入位置的时候就会产生竞争。上文说过，Disruptor采用CAS来保证游标的线程安全。直接上源码吧。这段源码应该是最能体现Disruptor核心设计思想的部分了。 com.lmax.disruptor.MultiProducerSequencer 1234567891011121314151617181920212223242526272829303132333435363738394041424344/** * @see Sequencer#next(int) */@Overridepublic long next(int n) //生产者申请分配n个位置{ if (n &lt; 1 || n &gt; bufferSize) { throw new IllegalArgumentException(\"n must be &gt; 0 and &lt; bufferSize\"); } long current; long next; do { current = cursor.get(); // cursor是已经分配的位置的头 next = current + n; // 待分配位置的头 long wrapPoint = next - bufferSize; // 待分配位置回退一圈的位置。用于和消费者的位置比较，避免把还没有读的位置也分配了 long cachedGatingSequence = gatingSequenceCache.get(); // 缓存的最慢消费者的位置 if (wrapPoint &gt; cachedGatingSequence || cachedGatingSequence &gt; current) // 如果缓存的最慢消费者的位置不符合条件，则重新进入检查 { long gatingSequence = Util.getMinimumSequence(gatingSequences, current); if (wrapPoint &gt; gatingSequence) // 最慢消费者的位置太小，会被生产者覆盖，因此不能完成分配，所以让出CPU。 { LockSupport.parkNanos(1); continue; } gatingSequenceCache.set(gatingSequence); } else if (cursor.compareAndSet(current, next)) // 设置新的游标位置！ 由于CAS的特性，多个生产者同时试图修改current游标的时候，只有一个会成功 // 其他的会重新进入循环，获取新的游标位置继续尝试申请。 { break; } } while (true); return next;} 进阶 Disruptor Wizard提供了一系列API来设置event handlers，并设置它们之间的依赖关系。 WaitStrategy 当消费者等待在SequenceBarrier上时，有许多可选的等待策略，不同的等待策略在延迟和CPU资源的占用上有所不同，可以视应用场景选择。 源码梳理3.x的代码，感兴趣的同学可以参考： https://zhanghaoxin.blog.csdn.net/article/category/6121943 ，对源码结构有较详细的讲解。或者参考 Disruptor 3.x源码梳理（简版） 参考资料 http://lmax-exchange.github.io/disruptor/files/Disruptor-1.0.pdf 论文 https://tech.meituan.com/2016/11/18/disruptor.html by美团技术团队 http://ifeve.com/disruptor/ 官网发布的系列文章的译文（比较老了，很多是根据1.x和2.x的讲解的，但是用来参考核心思想是没问题的）","link":"/blogs/2019/08/31/Disruptor介绍及原理讲解/"},{"title":"异步Servlet规范与Tomcat实现原理","text":"本篇比较流水账，但是也很详细具体，适合想要深入探索的人看。 异步Servlet的Why &amp; What有时候，Filter 及/或 Servlet 在生成响应之前必须等待一些资源或事件以便完成请求处理。比如，Servlet 在 进行生成一个响应之前可能等待一个可用的 JDBC 连接，或者一个远程 web 服务的响应，或者一个 JMS 消 息，或者一个应用程序事件。在 Servlet 中等待是一个低效的操作，因为这是阻塞操作，从而白白占用一个 线程或其他一些受限资源。 Servlet 3.0 引入了异步处理请求的能力，使线程可以返回到容器，从而执行更多的任务。一个典型的异步处理事件顺序是: 请求被接收到，通过一系列如用于验证的等标准的 filter 之后被传递到 Servlet。 2. servlet 处理请求参数及(或)内容体从而确定请求的类型。 该 servlet 发出请求去获取一些资源或数据，例如，发送一个远程 web 服务请求或加入一个等待 JDBC 连 接的队列。 4. servlet 不产生响应并返回。 过了一段时间后，所请求的资源变为可用，此时处理线程继续处理事件，要么在同一个线程，要么通过AsyncContext 分派到容器中的一个资源上。 Tomcat如何处理连接及对接servlet先说非异步的servlet线程池，异步servlet在此基础上进一步扩展。 EndPointEndPoint用于处理具体连接和传输数据，即用来实现网络连接和控制，它是服务器对外I/O操作的接入点。主要任务是管理对外的socket连接，同时将建立好的socket连接交到合适的工作线程中去。 里面两个主要的属性类是Acceptor和Poller、SocketProcessor。 我们以NioEndpoint为例，其内部请求处理具体的流程如下:展开时序图 Acceptor和PollerAcceptor和Poller都是实现了Runnable接口的类，在tomcat启动时，它们也作为线程start起来。 Acceptor接受到请求，用接收到的连接构造NioChannel对象，用该channel对象构造出PollerEvent，添加进Poller中 Poller的run函数，将注册的events逐个处理，将event对应的channel注册到某个Selector中(利用IO复用，进行读取)。selector.select()后，根据读取的SelectionKey，构造socketProcessor(实现了Runnable)，提交到tomcat线程池。而tomcat线程池中的socketProcessor被调度到后，经过一系列handler, processor的处理之后(验证\\http协议解析等)，最后对接到了HttpServlet上（对应tomcat-embed-core-8.5.43版本）:网上版本： 异步Servlet规范概要(以Servlet3.1规范为准)Servlet3.0开始，添加了一些方法/类以支持异步处理，这里列出一些比较关键的部分。 ServletRequest public AsyncContext startAsync(ServletRequest req, ServletResponse res)。这个方法的作用将请求转换为异步模式，并使用给定的请求及响应对象和 getAsyncTimeout 返回的超时时间初始化它的 AsyncContext。 AsyncContext public void addListener(AsyncListener listener, ServletRequest req, ServletResponse res) 。当超时/完成/出错会回调这里面的方法, 包含onTimeout, onError, onComplete 或 onStartAsync. public void dispatch(ServletContext context, String path) public void dispatch() public void dispatch(String path)以上为dispatch函数的三个变体，调用这些方法且将请求和响应对象传入到容器的一个托管线程后将立即返回，在托管线程中异步操作将被执行。请求的分派器类型设置为异步(ASYNC)。 控制委托给分派目标的请求和响应，除非调用了ServletRequest.startAsync() 或 ServletRequest.startAsync(ServletRequest, ServletResponse)，否则响应将在分派目标执行完成时被关闭。AsyncListener.onComplete(AsyncEvent), AsyncListener.onTimeout(AsyncEvent)和 AsyncListener.onError(AsyncEvent)的调用将被延迟到容器启动 的分派返回到容器之后。 public void complete() 。如果调用了 request.startAsync，则必须调用该方法以完成异步处理并提交和关闭响应。如果请求分派到一个不支持异步操作的 Servlet，或者由 AsyncContext.dispatch 调用的目标servlet 之后没有调用 startAsync，则 complete 方法会由容器调用。这种情况下，容器负责当 servlet 的 service 方法一退出就调用 complete()。 如果 startAsync 没有被调用则必须抛出 IllegalStateException。 在调用 ServletRequest.startAsync() 或 ServletRequest.startAsync(ServletRequest, ServletResponse) 之后且 在调用任意 dispatch 方法之前的任意时刻调用 complete()是合法的。 在tomcat中，dispatch和complete的具体实现与servlet规范有较大出入 规范中提到“调用这些方法且将请求和响应对象传入到容器的一个托管线程后将立即返回，在托管线程中异步操作将被执行。” 在tomcat中，dispatch函数实际上在异步操作完成后才会被执行，dispatch会托管一个线程给tomcat容器，该线程负责收尾工作。 规范中提到“如果调用了 request.startAsync，则必须调用该方法以完成异步处理并提交和关闭响应。如果请求分派到一个不支持异步操作的 Servlet，或者由 AsyncContext.dispatch 调用的目标servlet 之后没有调用 startAsync，则 complete 方法会由容器调用。这种情况下，容器负责当 servlet 的 service 方法一退出就调用 complete()。”。 在tomcat中，complete函数仅由业务实现者调用，如果业务实现者未调用，容器也不会负责调用。实际上，在这种情况下，本应由complete函数完成的收尾工作，实际是由dispatch函数完成的。（？？？？？？） 异步servlet与Tomcat线程池最基础的架子和之前说的非异步的servlet一样，只是每次请求都会进入tomcat线程池至少两次。 第一次进入tomcat线程池后，servlet的service方法执行完毕，从CoyoteAdapter返回时，此时根据状态机的状态判断是异步的，不会结束响应，但相应的tomcat线程会被释放。业务线程此时继续执行任务，直到通过AsyncContext.dispatch或者.complete()回调，该回调会将SocketProcessor再次注册到tomcat线程池中，相当于重新开启一个工作线程。而这一遍的流程，因为Servlet已经处理过，所以会略过servlet的执行，直接将后续处理走完，包括对response的收尾，对象的清空等等。以下以spring-boot的tomcat-embed 8.5.43版本为例，具体展开讲讲。 案例一我们的示例代码： 1234567@RequestMapping(\"/async\")public Callable&lt;BaseResponse&gt; callable() { return () -&gt; { Thread.sleep(1000); return StandardResponse.make(\"hello\"); };} 流水账开始……第一次SocketProcessor前面的流程和上文说的一样，Poller将SocketProcessor提交到tomcat线程池(由EndPoint持有)，然后socketProcessor被调度，执行其run方法，run方法调用doRun()。 在我们的示例中，spring框架会根据返回值，进入异步servlet的处理流程，调用栈如下： 1234567891011startAsync:121, StandardServletAsyncWebRequest (org.springframework.web.context.request.async)startAsyncProcessing:466, WebAsyncManager (org.springframework.web.context.request.async)……handleReturnValue:51, CallableMethodReturnValueHandler (org.springframework.web.servlet.mvc.method.annotation)handleReturnValue:82, HandlerMethodReturnValueHandlerComposite (org.springframework.web.method.support)invokeAndHandle:119, ServletInvocableHandlerMethod (org.springframework.web.servlet.mvc.method.annotation)……doDispatch:1038, DispatcherServlet (org.springframework.web.servlet)doService:942, DispatcherServlet (org.springframework.web.servlet)……service:634, HttpServlet (javax.servlet.http) StandardServletAsyncWebRequest的startAsync方法调用 HttpServletRequest.startAsync()：在tomcat中，每个请求对应一个AsyncState， 由AsyncStateMachine提供状态转换管理。 此处调用startAsync以后，asyncState 由 DISPATCHED → STARTING 返回到WebAsyncManager.startCallableProcessing 方法继续执行： 1234567891011121314151617181920212223242526public void startCallableProcessing(final WebAsyncTask&lt;?&gt; webAsyncTask, Object... processingContext) throws Exception { ... try { Future&lt;?&gt; future = this.taskExecutor.submit(() -&gt; { Object result = null; try { interceptorChain.applyPreProcess(this.asyncWebRequest, callable); result = callable.call(); } catch (Throwable ex) { result = ex; } finally { result = interceptorChain.applyPostProcess(this.asyncWebRequest, callable, result); } setConcurrentResultAndDispatch(result); }); interceptorChain.setTaskFuture(future); } catch (RejectedExecutionException ex) { Object result = interceptorChain.applyPostProcess(this.asyncWebRequest, callable, ex); setConcurrentResultAndDispatch(result); throw ex; }} 此处用我们返回的Callable创建一个task，提交给executor进行执行。 该task就相当于是我们的业务线程，业务部分执行结束后，setConcurrentResultAndDispatch函数调用asyncContext的dispatch函数，进行状态的更改和tomcat线程的重新提交： 12345678910public void dispatch(ServletContext servletContext, String path) { synchronized (asyncContextLock) { ... this.dispatch = new AsyncRunnable( request, applicationDispatcher, servletRequest, servletResponse); this.request.getCoyoteRequest().action(ActionCode.ASYNC_DISPATCH, null); clearServletRequestResponse(); context.decrementInProgressAsyncCount(); }} 此处action(ActionCode.ASYNC_DISPATCH, null)调用将asyncState由 STARTED → DISPATCHING，并再次将socketProcessor提交给tomat线程池。（注意此处设置了一个AsyncRunnable方法，会提供给第二次进入线程池时做调用） 回头继续看第一个线程，返回至AbstractProcessorLight后，调用AbstractProcessor.asyncPostProcess → AsyncStateMachine.asyncPostProcess, 状态由STARTING→ STARTED 通过isAsync判断，判断当前正在进行异步处理，进入CoyoteAdapter的asyncDispatch方法： 1234567891011121314151617@Overridepublic boolean asyncDispatch(org.apache.coyote.Request req, org.apache.coyote.Response res, SocketEvent status) throws Exception { ... try { ... if (!request.isAsync()) { request.finishRequest(); response.finishResponse(); } ... } catch (...) { ... }} 此处request.isAsync返回true，因此不结束响应 注：存在一种可能性，即在第一次线程开始返回之前，我们的业务线程就已经做完工作，此时业务线程对dispatch的调用会将STARTING→ DISPATCH_PENDING，同时不会再往tomcat中丢一个新的线程。然后第一个线程返回时，在asbstracProcessorLight.process()中，将状态由DISPATCH_PENDING → DISPATCHING → DISPATCHED, 达到终态。也就是说，在没有必要的情况下（业务线程及时执行完成了），就不会进入tomcat线程池两次了。 第二次SocketProcessor整体socketProcessor的调用时序还是和前文一致，返回至StandardWrapperValve中invoke函数时，进入asyncContextImpl的doInternalDispatch方法： 123456789101112131415protected void doInternalDispatch() throws ServletException, IOException { if (log.isDebugEnabled()) { logDebug(\"intDispatch\"); } try { Runnable runnable = dispatch; dispatch = null; runnable.run(); if (!request.isAsync()) { fireOnComplete(); } } catch (RuntimeException x) { ... }} 前文的futureTask设置的名为dispatch的AsyncRunnable在此被执行，在此方法中asyncState 由 DISPATCHING → DISPATCHED, 至此，该请求已达到终态，isAsync()返回为false。 于是进入fireOnComplete函数，此函数会调用之前注册过的asyncListener的onComplete函数。 … 再次进入CoyoteAdapter的asyncDispatch方法，request.isAsync返回false，此时结束响应，客户端得到返回，后续tomcat进行一些对象清理的操作。 案例二示例代码 123456789101112131415161718192021222324252627282930313233343536373839404142434445@WebServlet(name = \"simple\", value = {\"/simple\"}, asyncSupported = true)public class SimpleAsyncServlet extends HttpServlet { /** * Simply spawn a new thread (from the app server's pool) for every * new async request. Will consume a lot more threads for many * concurrent requests. */ @Override public void service(ServletRequest req, final ServletResponse res) { final AsyncContext asyncContext = req.startAsync(); asyncContext.setTimeout(30000); asyncContext.addListener(new AsyncListener() { @Override public void onComplete(AsyncEvent event) { log(\"onComplete called\"); } @Override public void onTimeout(AsyncEvent event) { log(\"onTimeout called\"); } @Override public void onError(AsyncEvent event) { log(\"onError called\"); } @Override public void onStartAsync(AsyncEvent event) { log(\"onStartAsync called\"); } }); asyncContext.start(() -&gt; { try { asyncContext.getResponse().getWriter().write(\"hello\"); } catch (IOException e) { log(\"Problem processing task\", e); } asyncContext.complete(); }); } 这里，我们自己控制整个异步过程，包括异步状态的打开（request.startAsync），业务线程内最后对asyncContext.complete()的调用以确认异步状态的结束等。 第一次SocketProcessor前面的部分依然一样，然后根据path路由到了我们定义的SimpleAsyncServlet.service()中。在这里，我们通过request.startAsync打开异步处理状态，初始化AsyncContext， DISPATCHED → STARTING asyncContext.start()将传入的Runnable参数，扔到tomcat线程池启动，也就是说该业务线程仍然会占用tomcat的线程池（因此实际中我们推荐自己管理一个业务线程池，将业务线程提交到业务线程池中，而不使用asyncContext.start的方式） 1234567891011121314public synchronized void asyncRun(Runnable runnable) { if (state == AsyncState.STARTING || state == AsyncState.STARTED || state == AsyncState.READ_WRITE_OP) { ... try { ... processor.getExecutor().execute(runnable); } finally { ... } } else { ... }} 然后后续在AbstractProcessorLight.process → AbstractProcessor.asyncPostProcess → AsyncStateMachine.asyncPostProcess, 这一段，将状态STARTING → STARTED 业务线程得到调度并执行完毕后， 调用asyncContext.complete()： 12345@Overridepublic void complete() { ... request.getCoyoteRequest().action(ActionCode.ASYNC_COMPLETE, null);} 这里进入asyncStateMachine.asyncComplete()方法， STARTED → COMPLETING, 然后在tomcat中提交新线程 注：同样地，在业务线程提前完成的情况下，asyncContext.complete → asyncStateMachine.asyncComplete()提前被调用， STARTING → COMPLETE_PENDING, 这种情况下不会再往tomcat线程池中提交新线程 回到第一个线程， 同样的在AbstractProcessorLight.process → AbstractProcessor.asyncPostProcess → AsyncStateMachine.asyncPostProcess, 这一段，将状态COMPLETE_PENDING → COMPLETING → DISPATCHED 第二次SocketProcessor类似案例一， 在AbstractProcessorLight.process → AbstractProcessor.asyncPostProcess → AsyncStateMachine.asyncPostProcess, 这一段，将状态COMPLETING → DISPATCHED， 达到终态 总结异步servlet的状态管理主要依靠ServletRequest . hook(Http11Processor)中记录的AsyncStateMachine，AsyncStateMachine中记录的AsyncState，从而判断当前是否isAsync\\isAsyncDispatching等等，从而控制线程的提交、响应的返回等。 一般情况下，为了处理一个异步servlet，总共需要开启三次线程，两次是SocketProcessor，提交到tomcat线程池中；一次是业务线程，用于做异步操作。第一次SocketProcessor由一直在监听请求的Acceptor创建，第一个SocketProcessor线程启动业务线程，业务线程再回调第二个SocketProcessor； 当业务线程执行提前完成时，第二个SocketProcessor就不会被提交了，所以是需要两个线程。","link":"/blogs/2019/08/31/异步Servlet规范与Tomcat实现原理/"}],"tags":[{"name":"Java, 高性能","slug":"Java-高性能","link":"/blogs/tags/Java-高性能/"},{"name":"Java","slug":"Java","link":"/blogs/tags/Java/"},{"name":"Tomcat","slug":"Tomcat","link":"/blogs/tags/Tomcat/"},{"name":"高性能","slug":"高性能","link":"/blogs/tags/高性能/"}],"categories":[]}